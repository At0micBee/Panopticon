window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "src", "modulename": "src", "kind": "module", "doc": "<h1 id=\"panopticon\">Panopticon</h1>\n\n<h1 id=\"description\">Description</h1>\n\n<p>Machine Learning pipeline for PLATO data. We use a CNN to analyze simulated data to prepare for real\ndata reduction in the near future.</p>\n\n<p>The project is currently under development, more features and usage cases are coming.</p>\n\n<hr />\n\n<h1 id=\"usage\">Usage</h1>\n\n<p>To install the required dependencies, use the <code>requirements.txt</code> file with the command:</p>\n\n<blockquote>\n  <p><code>pip install -r requirements.txt</code></p>\n</blockquote>\n\n<hr />\n\n<h2 id=\"machine-learning\">Machine learning</h2>\n\n<p>The machine learning portion of the code is accessed via the <code>main.py</code> program. A number of flags then dictate what to do.</p>\n\n<blockquote>\n  <p><code>--train</code></p>\n</blockquote>\n\n<p>Starts the training on the dataset.</p>\n\n<blockquote>\n  <p><code>--eval</code></p>\n</blockquote>\n\n<p>Starts evaluating the model using the parameters specified.</p>\n\n<h2 id=\"data-handling\">Data handling</h2>\n\n<p>The data analysis, visualization and preparation is done through the <code>data.py</code> program.</p>\n\n<blockquote>\n  <p><code>--plot [file_name]</code></p>\n</blockquote>\n\n<p>This flags set the program in plotting mode, which is used to generate the visual of the light curves\nfrom the simulations. It can be called using the name(s) of the simulation file(s) to use (<em>e.g.</em>\n<code>--plot sim00001_Q1.ftr sim00002_Q1.ftr</code>) or directly for all available files (<code>--plot all</code>).</p>\n\n<p>To simplify the process, the latest run can be accessed by using <code>--plot last</code>.</p>\n\n<blockquote>\n  <p><code>--plotall</code></p>\n</blockquote>\n\n<p>Runs the plotting routine on all files available.</p>\n\n<blockquote>\n  <p><code>--analyze [file_name]</code></p>\n</blockquote>\n\n<p>Similar syntax to the <code>--plot</code> flag, but for the analysis of a run.</p>\n\n<p>To prepare data for a run, follow these steps</p>\n\n<p>First, open the <code>param_maker.ipynb</code> notebook and generate the <code>Complete_parameters.ftr</code> file (make sure to have all the <code>AllParameters</code> files from the simulations).</p>\n\n<p>Then run the label creator, which will create the ML model targets, and the packaging operation, which will format them into the required formats for the training and testing.</p>\n\n<pre><code>python data.py --labels\npython data.py --prepare (--augment --filter_inf)\n</code></pre>\n\n<p>The <code>--filter_inf</code> flag removes <code>NaN</code> to avoid gradient computation errors, and <code>--augment</code> creates the inverted time series of a given LC using spline fitting.</p>\n\n<h2 id=\"secondary-flags\">Secondary flags</h2>\n\n<blockquote>\n  <p><code>--cfg path/to/config.toml</code></p>\n</blockquote>\n\n<p>The <code>--cfg</code> flag is used to pass the path to a configuration file. If not specified, the default\nfile (<code>./config/default.toml</code>). For a description on what is in the configuration file,\nsee the <a href=\"##configuration-file\">dedicated section</a>.</p>\n\n<hr />\n\n<h1 id=\"configuration-file\">Configuration file</h1>\n\n<p>The configuration file is a <code>toml</code> file used to pass key information to run the program. Each entry is\ndescribed in the file itself, but here is a quick overview. By default the program uses the <code>default.toml</code>\nfile, to pass a custom one, use <code>--cfg ./path/to/your/file.toml</code> when calling the program.</p>\n\n<blockquote>\n  <p><code>path_data</code>: is the path to the raw simulation files</p>\n</blockquote>\n\n<blockquote>\n  <p><code>path_prepared</code>: is the path to the prepared data for training</p>\n</blockquote>\n\n<blockquote>\n  <p><code>path_output</code>: The path where the output of the training is written</p>\n</blockquote>\n\n<blockquote>\n  <p><code>seed</code>: is the seed to use for the splitting of the datasets (used for reproducibility)</p>\n</blockquote>\n\n<blockquote>\n  <p><code>training_epochs</code>: maximum number of epochs during training</p>\n</blockquote>\n\n<blockquote>\n  <p><code>[fraction]</code>: are the values corresponding to the proportion of training, validation and testing</p>\n</blockquote>\n\n<blockquote>\n  <p><code>[dataloaders]</code>: kwargs to pass when creating the torch DataLoaders\n  (see <a href=\"https://pytorch.org/docs/stable/data.html\">docs</a>)</p>\n</blockquote>\n\n<blockquote>\n  <p><code>[optimizer]</code>: the optimizer to use during training\n  (and its parameters, <a href=\"https://pytorch.org/docs/stable/optim.html\">docs</a>)</p>\n</blockquote>\n\n<blockquote>\n  <p><code>[scheduler]</code>: the scheduler to use during training\n  (and its parameters, <a href=\"https://pytorch.org/docs/stable/optim.html\">docs</a>)</p>\n</blockquote>\n\n<p>If you are not familiar with <code>toml</code>, <a href=\"https://toml.io/en/\">here is the documentation</a>. In essence, it's \na very practical format to write a few parameters down without having to hard code them in the\nsource code. It also makes it easy to create multiple sets of parameters if the code runs on various\nmachines, for various people.</p>\n\n<hr />\n\n<h1 id=\"other-commands\">Other commands</h1>\n\n<p>The documentation is built with <a href=\"https://pdoc.dev/docs/pdoc.html\"><code>pdoc</code></a>, to generate it,\nuse the command:</p>\n\n<blockquote>\n  <p><code>pdoc ./src -o ./docs -t ./doc_theme</code></p>\n</blockquote>\n\n<p>To generate the requirements, use <code>pipreqs</code>:</p>\n\n<blockquote>\n  <p><code>pipreqs ./src</code></p>\n</blockquote>\n\n<p>and to install them all, use:</p>\n\n<blockquote>\n  <p><code>pip install -r ./requirements.txt</code></p>\n</blockquote>\n\n<p>--</p>\n\n<h1 id=\"todo-add-license\">TODO: add license</h1>\n\n<h1 id=\"authors\">Authors</h1>\n\n<p>Codebase written by Hugo G. Vivien (Laboratoire d'Astrophysique de Marseille),\nunder the supervision of Magali Deleuil.</p>\n\n<hr />\n"}, {"fullname": "src.constants", "modulename": "src.constants", "kind": "module", "doc": "<h1 id=\"constants\">Constants</h1>\n"}, {"fullname": "src.constants.NUM_CPU", "modulename": "src.constants", "qualname": "NUM_CPU", "kind": "variable", "doc": "<h1 id=\"get-the-number-of-available-cpu\">Get the number of available cpu</h1>\n\n<p>Checks if we are on the cluster, falls back to default methods if necessary.</p>\n", "default_value": " = 16"}, {"fullname": "src.constants.PATH_LOCAL", "modulename": "src.constants", "qualname": "PATH_LOCAL", "kind": "variable", "doc": "<h1 id=\"path-to-currently-running-file\">Path to currently running file</h1>\n\n<p>It is computed using <code>os.path.dirname(__file__)</code>, for compatibility.</p>\n", "default_value": " = &#x27;/home/hvivien/Documents/Codes/python/panopticon/src&#x27;"}, {"fullname": "src.constants.PATH_CONFIG", "modulename": "src.constants", "qualname": "PATH_CONFIG", "kind": "variable", "doc": "<h1 id=\"configuration-file-path\">Configuration file path</h1>\n\n<p>Computed from the <code>PATH_LOCAL</code> value. The path to the default config file.\nIf none are specified when running the program, this is the one used.</p>\n", "default_value": " = &#x27;/home/hvivien/Documents/Codes/python/panopticon/config/default.toml&#x27;"}, {"fullname": "src.constants.PATH_OUT", "modulename": "src.constants", "qualname": "PATH_OUT", "kind": "variable", "doc": "<h1 id=\"output-path\">Output path</h1>\n\n<p>Computed from the <code>PATH_LOCAL</code> value. The root used to save the results of the model.\nA sub folder will be generated for each run, based on the start time of the program.</p>\n", "default_value": " = &#x27;/home/hvivien/Documents/Codes/python/panopticon/out&#x27;"}, {"fullname": "src.constants.PATH_FIGS", "modulename": "src.constants", "qualname": "PATH_FIGS", "kind": "variable", "doc": "<h1 id=\"generated-figures-path\">Generated figures path</h1>\n\n<p>Computed from the <code>PATH_LOCAL</code> value. Where the generated figures are saved.</p>\n", "default_value": " = &#x27;/home/hvivien/Documents/Codes/python/panopticon/figs&#x27;"}, {"fullname": "src.constants.PATH_PREPARED", "modulename": "src.constants", "qualname": "PATH_PREPARED", "kind": "variable", "doc": "<h1 id=\"the-path-to-where-all-the-data-is-stored\">The path to where all the data is stored</h1>\n", "default_value": " = &#x27;/data/Plato_sim_data&#x27;"}, {"fullname": "src.constants.SLICE", "modulename": "src.constants", "qualname": "SLICE", "kind": "variable", "doc": "<h1 id=\"the-slice-used-to-obtain-the-flux-of-the-cameras-in-the-dataframes\">The slice used to obtain the flux of the cameras in the Dataframes.</h1>\n\n<p>So far, we need to skip the zeroth column (<code>time</code>), and the last (<code>coaddition</code>). If the slice becomes\nmore verbose in a future version, it seems easier to have a single instance to modify.</p>\n", "default_value": " = slice(1, -1, None)"}, {"fullname": "src.constants.SIMS_PARAMS", "modulename": "src.constants", "qualname": "SIMS_PARAMS", "kind": "variable", "doc": "<h1 id=\"additional-simulation-parameters-to-put-in-the-reference-file\">Additional simulation parameters to put in the reference file</h1>\n\n<p>The parameters to add to the reference file, other than the light curve and the reference classes.</p>\n", "default_value": " = [&#x27;radius_star&#x27;, &#x27;Teff&#x27;, &#x27;logg&#x27;, &#x27;logRHK&#x27;, &#x27;radius_planet&#x27;]"}, {"fullname": "src.constants.THRESHOLDS", "modulename": "src.constants", "qualname": "THRESHOLDS", "kind": "variable", "doc": "<h1 id=\"the-detection-thresholds\">The detection thresholds</h1>\n\n<p>The cutoff for the validation detection.</p>\n", "default_value": " = tensor([0.0500, 0.1000, 0.1500, 0.2000, 0.2500, 0.3000, 0.3500, 0.4000, 0.4500,\n        0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,\n        0.9500])"}, {"fullname": "src.constants.THRESHOLD_BOX", "modulename": "src.constants", "qualname": "THRESHOLD_BOX", "kind": "variable", "doc": "<h1 id=\"box-iou-threshold\">Box IOU threshold</h1>\n\n<p>We check if the detected box IOU is greater than this value.</p>\n", "default_value": " = 0.5"}, {"fullname": "src.constants.STD_DURATION", "modulename": "src.constants", "qualname": "STD_DURATION", "kind": "variable", "doc": "<h1 id=\"duration-of-a-tce\">Duration of a TCE</h1>\n\n<p>The delta is in number of points in the LC, as of the writing of the code, the LC have\na 1 minute sampling, so it translates to minutes. If the sampling changes, please be aware\nthat this value needs to change!</p>\n\n<p>1200 = 20 hours</p>\n", "default_value": " = 1200"}, {"fullname": "src.constants.SEC_DAY", "modulename": "src.constants", "qualname": "SEC_DAY", "kind": "variable", "doc": "<h1 id=\"seconds-in-a-day\">Seconds in a day</h1>\n\n<p>Used to scale plots to be more readable.</p>\n", "default_value": " = 86400"}, {"fullname": "src.constants.Q_LENGTH", "modulename": "src.constants", "qualname": "Q_LENGTH", "kind": "variable", "doc": "<h1 id=\"quarter-length\">Quarter length</h1>\n", "default_value": " = 7603200"}, {"fullname": "src.constants.Q_SHIFT", "modulename": "src.constants", "qualname": "Q_SHIFT", "kind": "variable", "doc": "<h1 id=\"shift-between-two-quarters\">Shift between two quarters</h1>\n", "default_value": " = 43200.0"}, {"fullname": "src.model", "modulename": "src.model", "kind": "module", "doc": "<h1 id=\"panopticon\">Panopticon</h1>\n\n<p>The building blocks for the model and its dependencies.</p>\n"}, {"fullname": "src.model.dataset", "modulename": "src.model.dataset", "kind": "module", "doc": "<h1 id=\"dataset-for-plato-sim\">Dataset for Plato Sim</h1>\n"}, {"fullname": "src.model.dataset.LightCurveSet", "modulename": "src.model.dataset", "qualname": "LightCurveSet", "kind": "class", "doc": "<h1 id=\"dataset-handling-plato-light-curves\">Dataset handling Plato light curves</h1>\n\n<p>Using the prepared data from the pipeline, see the <code>readme</code> for more info.</p>\n", "bases": "typing.Generic[+T_co]"}, {"fullname": "src.model.dataset.LightCurveSet.__init__", "modulename": "src.model.dataset", "qualname": "LightCurveSet.__init__", "kind": "function", "doc": "<h1 id=\"dataset-initialization\">Dataset initialization</h1>\n\n<p>We load the light curves and their labels. We load the entirety of the available data in a single dataset,\nsplitting the data into <code>Subsets</code> later on. This simplifies the loading process and ensures reproducibility\nof each required <code>Subset</code>.</p>\n\n<ul>\n<li><code>path</code>: The path to the directory containing all the light curves to use.</li>\n<li><code>transform</code>: The transformation to apply on the input.</li>\n<li><code>target_transform</code>: The transformation to apply on the labels.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">transform</span><span class=\"o\">=</span><span class=\"kc\">None</span>, </span><span class=\"param\"><span class=\"n\">target_transform</span><span class=\"o\">=</span><span class=\"kc\">None</span></span>)</span>"}, {"fullname": "src.model.dataset.LightCurveSet.normalize", "modulename": "src.model.dataset", "qualname": "LightCurveSet.normalize", "kind": "function", "doc": "<h1 id=\"normalizing-a-curve\">Normalizing a curve</h1>\n\n<p>Computes the normalization of an input vector in the range [0, 1], based on the min and max\nof the given vector. Note that the function also reshapes and casts the values to <code>f32</code>.</p>\n\n<ul>\n<li><code>curve</code>: the light curve to normalize, of shape [N].</li>\n</ul>\n\n<p>Returns a <code>Tensor</code> of shape [1, N], with values between 0 and 1.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">curve</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.model.dataset.LightCurveSet.load_lc", "modulename": "src.model.dataset", "qualname": "LightCurveSet.load_lc", "kind": "function", "doc": "<h1 id=\"loads-a-lightcurve-and-its-metadata-from-a-given-path\">Loads a lightcurve and its metadata from a given path</h1>\n\n<p>Given the path to a properly formatted data file, this function loads the lightcurve and its corresponding\nmetadata. The data returned is processed (using <code>LightCurveSet.normalize</code>), and having a public method\naccessible from other modules ensures a single, unique, function to avoid inconsistencies or errors from\nother implementations.</p>\n\n<ul>\n<li><code>lc_name</code>: the path to the desired light curve file.</li>\n</ul>\n\n<p>Returns a tuple of data:</p>\n\n<ul>\n<li><code>lc_name</code>: the path of the processed data.</li>\n<li><code>sim_params</code>: the metadata of the simulation (planetary radius, stellar temperature, etc...).</li>\n<li><code>lc</code>: the normalized light curve.</li>\n<li><code>ref</code>: the reference for inference.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">lc_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"nb\">dict</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.model.functions", "modulename": "src.model.functions", "kind": "module", "doc": "<h1 id=\"training-routines-for-the-models\">Training routines for the models</h1>\n"}, {"fullname": "src.model.functions.Run", "modulename": "src.model.functions", "qualname": "Run", "kind": "class", "doc": "<h1 id=\"setting-up-the-running-environment-for-training\">Setting up the running environment for training</h1>\n\n<h2 id=\"description\">Description</h2>\n\n<h2 id=\"inputs\">Inputs</h2>\n\n<ul>\n<li><code>cfg</code>: The configuration file loaded</li>\n<li><code>time_start</code>: The stamp of the program start</li>\n</ul>\n\n<p>Returns the parameters required to run a training or testing job.</p>\n"}, {"fullname": "src.model.functions.Run.__init__", "modulename": "src.model.functions", "qualname": "Run.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">cfg</span><span class=\"p\">:</span> <span class=\"nb\">dict</span>, </span><span class=\"param\"><span class=\"n\">time_start</span><span class=\"p\">:</span> <span class=\"n\">datetime</span><span class=\"o\">.</span><span class=\"n\">datetime</span></span>)</span>"}, {"fullname": "src.model.functions.Run.train", "modulename": "src.model.functions", "qualname": "Run.train", "kind": "function", "doc": "<h1 id=\"training-the-model\">Training the model</h1>\n\n<p>Using the requested dataset (split into a training and validation <code>Subsets</code>), we update the model's weights.\nAll the relevant parameters are supplied on the <code>Run</code> class, and the <code>train</code> function therefore requires\nno additional parameters.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.model.functions.Run.validate", "modulename": "src.model.functions", "qualname": "Run.validate", "kind": "function", "doc": "<h1 id=\"testing-a-model-on-a-given-subset\">Testing a model on a given <code>Subset</code></h1>\n\n<p>We go through the validation dataset to test the performance of the model.\nIn standard operation, the function is called at every training epoch.</p>\n\n<p>The function uses the <code>@torch.no_grad()</code> decorator to disable <code>Tensor</code> gradient computation,\nwhich isn't necessary during testing. The model is also flipped in <code>model.eval()</code> mode at the\nbeginning of the function, and set back to <code>model.train()</code> mode before returning.</p>\n\n<ul>\n<li><code>epoch</code>: the current epoch counter, for book-keeping.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">epoch</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.model.functions.Run.info", "modulename": "src.model.functions", "qualname": "Run.info", "kind": "function", "doc": "<h1 id=\"prints-out-info-about-the-model\">Prints out info about the model</h1>\n\n<p>We show the default version, using <code>print(model)</code>, and a more detailed implementation in the\n<code>torchsummary</code> module.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">shape</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.model.loss", "modulename": "src.model.loss", "kind": "module", "doc": "<h1 id=\"loss-functions\">Loss functions</h1>\n\n<p>This module compiles loss functions that can be used to train the model. They are all written \nas a <code>torch.nn.Module</code> class, for interoperability.</p>\n"}, {"fullname": "src.model.loss.DiceLoss", "modulename": "src.model.loss", "qualname": "DiceLoss", "kind": "class", "doc": "<h1 id=\"dice-loss-implementation\">Dice loss implementation</h1>\n\n<p>Similar (and, in fact, usually equivalent) to the IOU. Allows to compute the loss based on a specific metric\nrather than just the Binary Cross Entropy.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "src.model.loss.DiceLoss.__init__", "modulename": "src.model.loss", "qualname": "DiceLoss.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">()</span>"}, {"fullname": "src.model.loss.DiceLoss.forward", "modulename": "src.model.loss", "qualname": "DiceLoss.forward", "kind": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">predictions</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"n\">reference</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.model.loss.Loss", "modulename": "src.model.loss", "qualname": "Loss", "kind": "class", "doc": "<h1 id=\"loss-function-for-panopticon\">Loss function for Panopticon</h1>\n\n<p>Currently simply using the BCE loss implementation of <code>torch</code>.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "src.model.loss.Loss.__init__", "modulename": "src.model.loss", "qualname": "Loss.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">device</span></span>)</span>"}, {"fullname": "src.model.loss.Loss.forward", "modulename": "src.model.loss", "qualname": "Loss.forward", "kind": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">prediction</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"n\">reference</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.model.model", "modulename": "src.model.model", "kind": "module", "doc": "<h1 id=\"models\">Models</h1>\n\n<p>All variants of the model are defined here. The core model is based upon a <code>Unet</code> architecture, or\nits variants (<code>Unet++</code>, <code>Unet3+</code>, ...).</p>\n\n<p>The goal of the model it to produce a probability map with a one-to-one correspondance with the input\nlight curve. Each point is assigned a probability to belong to a transit event. A value of zero indicates\nthat the point belongs to the continuum, while a value of one means that the point is inside of a transit.</p>\n\n<p>As per <code>torch</code> computational format, the required input is of shape <code>[B, F, P]</code>, with <code>B</code> the batch size,\n<code>F</code> the number of input features and <code>P</code> to length of the time series.</p>\n"}, {"fullname": "src.model.model.load_from_params", "modulename": "src.model.model", "qualname": "load_from_params", "kind": "function", "doc": "<h1 id=\"loading-the-correct-model-using-the-internals\">Loading the correct model using the internals</h1>\n\n<p>This allows being flexible using state_dict of each model, and avoids\nrelying on saving/loading the model directly, which can break things\nvery easily.</p>\n\n<p>It can be used to initialize a model, either by name alone or with a specific internal structure. If \nthe model is specified by name alone, the internal structure will be attributed using the current\ndefault values in the model definitions.</p>\n\n<ul>\n<li><code>internals</code>: the <code>dict</code> with the internal parameters of the model (obtained using <code>model.export_values()</code>)</li>\n<li><code>name</code>: the <code>str</code> name of the model to use (<code>Panopticon_U3P</code>, for example)</li>\n</ul>\n\n<p>Returns the requested model class, with or without specified internal parameters.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">internals</span><span class=\"p\">:</span> <span class=\"nb\">dict</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"n\">src</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">Panopticon_U</span> <span class=\"o\">|</span> <span class=\"n\">src</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">Panopticon_UPP</span> <span class=\"o\">|</span> <span class=\"n\">src</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">Panopticon_U3P</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.model.model.Panopticon_U", "modulename": "src.model.model", "qualname": "Panopticon_U", "kind": "class", "doc": "<h1 id=\"panopticon-unet-architecture\">Panopticon, Unet architecture</h1>\n\n<p>Using the Unet architecture, identifies features and returns them on a 1:1 output map.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "src.model.model.Panopticon_U.__init__", "modulename": "src.model.model", "qualname": "Panopticon_U.__init__", "kind": "function", "doc": "<h1 id=\"panopticon-unet-initialization\">Panopticon (Unet) initialization</h1>\n\n<ul>\n<li><code>internals</code>: the <code>dict</code> with the internal parameters of the model (obtained using <code>model.export_values()</code>)</li>\n</ul>\n\n<p>If <code>internals</code> is not specified, the model will be created using the default values defined in <code>__init__()</code>.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">internals</span><span class=\"p\">:</span> <span class=\"nb\">dict</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "src.model.model.Panopticon_U.forward", "modulename": "src.model.model", "qualname": "Panopticon_U.forward", "kind": "function", "doc": "<h1 id=\"forward-pass-at-every-call\">Forward pass at every call</h1>\n\n<p>Note (from <code>torch</code> documentation): this method shouldn't be called directly, but prediction should\nuse the module call directly, e.g. <code>Panopticon_U(x)</code>, as it ensures all registered hooks are ran properly.</p>\n\n<p><code>x</code>: the input to evaluate, shape <code>[B, F, P]</code> (see module docs for details)</p>\n\n<p>Returns the class probability for each point.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.model.model.Panopticon_U.export_values", "modulename": "src.model.model", "qualname": "Panopticon_U.export_values", "kind": "function", "doc": "<h1 id=\"internal-parameters-export\">Internal parameters export</h1>\n\n<p>Returns the <code>dict</code> of the parameters used in the model to re-create it easily a posteriori.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">dict</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.model.model.Panopticon_UPP", "modulename": "src.model.model", "qualname": "Panopticon_UPP", "kind": "class", "doc": "<h1 id=\"panopticon-unet-architecture\">Panopticon, Unet++ architecture</h1>\n\n<p>Using the Unet++ architecture, identifies features and returns them on a 1:1 output map.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "src.model.model.Panopticon_UPP.__init__", "modulename": "src.model.model", "qualname": "Panopticon_UPP.__init__", "kind": "function", "doc": "<h1 id=\"panopticon-unet-initialization\">Panopticon (Unet++) initialization</h1>\n\n<ul>\n<li><code>internals</code>: the <code>dict</code> with the internal parameters of the model (obtained using <code>model.export_values()</code>)</li>\n</ul>\n\n<p>If <code>internals</code> is not specified, the model will be created using the default values defined in <code>__init__()</code>.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">internals</span><span class=\"p\">:</span> <span class=\"nb\">dict</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "src.model.model.Panopticon_UPP.forward", "modulename": "src.model.model", "qualname": "Panopticon_UPP.forward", "kind": "function", "doc": "<h1 id=\"forward-pass-at-every-call\">Forward pass at every call</h1>\n\n<p>Note (from <code>torch</code> documentation): this method shouldn't be called directly, but prediction should\nuse the module call directly, e.g. <code>Panopticon_UPP(x)</code>, as it ensures all registered hooks are ran properly.</p>\n\n<p><code>x</code>: the input to evaluate, shape <code>[B, F, P]</code> (see module docs for details)</p>\n\n<p>Returns the class probability for each point.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.model.model.Panopticon_UPP.export_values", "modulename": "src.model.model", "qualname": "Panopticon_UPP.export_values", "kind": "function", "doc": "<h1 id=\"internal-parameters-export\">Internal parameters export</h1>\n\n<p>Returns the <code>dict</code> of the parameters used in the model to re-create it easily a posteriori.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">dict</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.model.model.Panopticon_U3P", "modulename": "src.model.model", "qualname": "Panopticon_U3P", "kind": "class", "doc": "<h1 id=\"panopticon-unet3-architecture\">Panopticon, Unet3+ architecture</h1>\n\n<p>Using the Unet3+ architecture, identifies features and returns them on a 1:1 output map.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "src.model.model.Panopticon_U3P.__init__", "modulename": "src.model.model", "qualname": "Panopticon_U3P.__init__", "kind": "function", "doc": "<h1 id=\"panopticon-unet3-initialization\">Panopticon (Unet3+) initialization</h1>\n\n<ul>\n<li><code>internals</code>: the <code>dict</code> with the internal parameters of the model (obtained using <code>model.export_values()</code>)</li>\n</ul>\n\n<p>If <code>internals</code> is not specified, the model will be created using the default values defined in <code>__init__()</code>.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">internals</span><span class=\"p\">:</span> <span class=\"nb\">dict</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "src.model.model.Panopticon_U3P.forward", "modulename": "src.model.model", "qualname": "Panopticon_U3P.forward", "kind": "function", "doc": "<h1 id=\"forward-pass-at-every-call\">Forward pass at every call</h1>\n\n<p>Note (from <code>torch</code> documentation): this method shouldn't be called directly, but prediction should\nuse the module call directly, e.g. <code>Panopticon_U3P(x)</code>, as it ensures all registered hooks are ran properly.</p>\n\n<p><code>x</code>: the input to evaluate, shape <code>[B, F, P]</code> (see module docs for details)</p>\n\n<p>Returns the class probability for each point.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.model.model.Panopticon_U3P.export_values", "modulename": "src.model.model", "qualname": "Panopticon_U3P.export_values", "kind": "function", "doc": "<h1 id=\"internal-parameters-export\">Internal parameters export</h1>\n\n<p>Returns the <code>dict</code> of the parameters used in the model to re-create it easily a posteriori.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">dict</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.model.model.Panopticon_U3P.get_num_feature", "modulename": "src.model.model", "qualname": "Panopticon_U3P.get_num_feature", "kind": "function", "doc": "<p>Pre-computing the number of features for each level</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">init_features</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.model.model.Block", "modulename": "src.model.model", "qualname": "Block", "kind": "class", "doc": "<h1 id=\"convolution-blocks-for-unets\">Convolution blocks for Unets</h1>\n\n<p>This block applies two convolution in a row of the same shape.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "src.model.model.Block.__init__", "modulename": "src.model.model", "qualname": "Block.__init__", "kind": "function", "doc": "<h1 id=\"block-initialization\">Block initialization</h1>\n\n<p><code>in_channels</code>: the number of input channels of the block\n<code>features</code>: the number of output channels of the block\n<code>param_conv</code>: the required parameters for the convolution sub-blocks</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">in_channels</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">features</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">param_conv</span><span class=\"p\">:</span> <span class=\"nb\">dict</span></span>)</span>"}, {"fullname": "src.model.model.Block.forward", "modulename": "src.model.model", "qualname": "Block.forward", "kind": "function", "doc": "<h1 id=\"forward-pass-at-every-call\">Forward pass at every call</h1>\n\n<p>Note (from <code>torch</code> documentation): this method shouldn't be called directly, but prediction should\nuse the module call directly, e.g. <code>Block(x)</code>, as it ensures all registered hooks are ran properly.</p>\n\n<p><code>x</code>: the input to evaluate, shape <code>[B, F, P]</code> (see module docs for details)</p>\n\n<p>Returns the double convolution block of the input.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.model.model.BlockSingle", "modulename": "src.model.model", "qualname": "BlockSingle", "kind": "class", "doc": "<h1 id=\"convolution-blocks-for-unets-single-conv\">Convolution blocks for Unets, single conv</h1>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "src.model.model.BlockSingle.__init__", "modulename": "src.model.model", "qualname": "BlockSingle.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">in_channels</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">features</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">param_conv</span><span class=\"p\">:</span> <span class=\"nb\">dict</span></span>)</span>"}, {"fullname": "src.model.model.BlockSingle.forward", "modulename": "src.model.model", "qualname": "BlockSingle.forward", "kind": "function", "doc": "<h1 id=\"forward-pass-at-every-call\">Forward pass at every call</h1>\n\n<p>Note (from <code>torch</code> documentation): this method shouldn't be called directly, but prediction should\nuse the module call directly, e.g. <code>BlockSingle(x)</code>, as it ensures all registered hooks are ran properly.</p>\n\n<p><code>x</code>: the input to evaluate, shape <code>[B, F, P]</code> (see module docs for details)</p>\n\n<p>Returns the convolution block of the input.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.model.selector", "modulename": "src.model.selector", "kind": "module", "doc": "<h1 id=\"listing-options-for-optimizer-and-scheduler\">Listing options for optimizer and scheduler</h1>\n"}, {"fullname": "src.utils", "modulename": "src.utils", "kind": "module", "doc": "<h1 id=\"utilities\">Utilities</h1>\n\n<p>This sub modules compiles some functions to manage the light curves\nof the simulation.</p>\n"}, {"fullname": "src.utils.analyzer", "modulename": "src.utils.analyzer", "kind": "module", "doc": "<h1 id=\"analyzer\">Analyzer</h1>\n\n<p>We load the output data of the model and plot relevant information to be visualized.</p>\n"}, {"fullname": "src.utils.analyzer.Output", "modulename": "src.utils.analyzer", "qualname": "Output", "kind": "class", "doc": "<h1 id=\"output-analysis-class\">Output analysis class</h1>\n\n<p>Loads a given output directory and the associated files. We compute the desired\nmetrics for analysis and plot them for visualization.</p>\n"}, {"fullname": "src.utils.analyzer.Output.__init__", "modulename": "src.utils.analyzer", "qualname": "Output.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "src.utils.analyzer.Output.process", "modulename": "src.utils.analyzer", "qualname": "Output.process", "kind": "function", "doc": "<h1 id=\"processes-the-output-in-its-entirety\">Processes the output in its entirety</h1>\n\n<p>We compute the metrics here, and use them to evaluate the model. We also\ncall the related plotting function for visualization.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utils.analyzer.Output.save_to_pickle", "modulename": "src.utils.analyzer", "qualname": "Output.save_to_pickle", "kind": "function", "doc": "<h1 id=\"saves-a-fig-to-pickle\">Saves a fig to pickle</h1>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">obj</span>, </span><span class=\"param\"><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utils.analyzer.Output.plot_loss", "modulename": "src.utils.analyzer", "qualname": "Output.plot_loss", "kind": "function", "doc": "<h1 id=\"plotting-the-loss-over-time\">Plotting the loss over time</h1>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utils.analyzer.Output.plot_prec_recall", "modulename": "src.utils.analyzer", "qualname": "Output.plot_prec_recall", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utils.analyzer.Output.plot_f1", "modulename": "src.utils.analyzer", "qualname": "Output.plot_f1", "kind": "function", "doc": "<h1 id=\"plotting-the-f1-score\">Plotting the f1 score</h1>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utils.analyzer.Output.plot_ap", "modulename": "src.utils.analyzer", "qualname": "Output.plot_ap", "kind": "function", "doc": "<h1 id=\"plotting-the-average-precision\">Plotting the average precision</h1>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utils.analyzer.Output.plot_iou", "modulename": "src.utils.analyzer", "qualname": "Output.plot_iou", "kind": "function", "doc": "<h1 id=\"plotting-the-jaccard-score-over-time\">Plotting the jaccard score over time</h1>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utils.analyzer.Output.plot_matrix", "modulename": "src.utils.analyzer", "qualname": "Output.plot_matrix", "kind": "function", "doc": "<h1 id=\"plotting-the-confusion-matrix\">Plotting the confusion matrix</h1>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utils.analyzer.Output.threshold_values", "modulename": "src.utils.analyzer", "qualname": "Output.threshold_values", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utils.analyzer.Output.plot_recovery", "modulename": "src.utils.analyzer", "qualname": "Output.plot_recovery", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utils.analyzer.analyze", "modulename": "src.utils.analyzer", "qualname": "analyze", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"n\">cfg</span><span class=\"p\">:</span> <span class=\"nb\">dict</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utils.data", "modulename": "src.utils.data", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.utils.data.Quarter", "modulename": "src.utils.data", "qualname": "Quarter", "kind": "class", "doc": "<h1 id=\"a-quarter-of-observation\">A quarter of observation</h1>\n"}, {"fullname": "src.utils.data.Quarter.__init__", "modulename": "src.utils.data", "qualname": "Quarter.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">ref</span><span class=\"p\">:</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span></span>)</span>"}, {"fullname": "src.utils.data.Quarter.compute_passes", "modulename": "src.utils.data", "qualname": "Quarter.compute_passes", "kind": "function", "doc": "<h1 id=\"visible-passes-computer\">Visible passes computer</h1>\n\n<p>We compute for the quarter the transit events on the lc.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">t0</span><span class=\"p\">:</span> <span class=\"nb\">float</span>, </span><span class=\"param\"><span class=\"n\">period</span><span class=\"p\">:</span> <span class=\"nb\">float</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.utils.data.Quarter.make_label", "modulename": "src.utils.data", "qualname": "Quarter.make_label", "kind": "function", "doc": "<h1 id=\"creates-the-label-for-the-quarter\">Creates the label for the quarter</h1>\n\n<p>We use t0 and the period to see which points belong to which event,\nand return the corresponding tensor as output.</p>\n\n<p>We create the position of the classes on the time series.</p>\n\n<ul>\n<li>0: the position of the transits</li>\n<li>1: the position of the EBs</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.utils.data.LightCurves", "modulename": "src.utils.data", "qualname": "LightCurves", "kind": "class", "doc": "<h1 id=\"plato-light-curve\">Plato light curve</h1>\n\n<p>Combines all quarters of a simulation.</p>\n"}, {"fullname": "src.utils.data.LightCurves.__init__", "modulename": "src.utils.data", "qualname": "LightCurves.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">id_sim</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">path_files</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">ref_df</span><span class=\"p\">:</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span></span>)</span>"}, {"fullname": "src.utils.data.LightCurves.n_cam_groups", "modulename": "src.utils.data", "qualname": "LightCurves.n_cam_groups", "kind": "function", "doc": "<h1 id=\"number-of-camera\">Number of camera</h1>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">int</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.utils.data.LightCurves.draw_ax", "modulename": "src.utils.data", "qualname": "LightCurves.draw_ax", "kind": "function", "doc": "<h1 id=\"unified-function-to-draw-each-ax\">Unified function to draw each ax</h1>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">ax</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>, </span><span class=\"param\"><span class=\"n\">q</span><span class=\"p\">:</span> <span class=\"n\">src</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Quarter</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utils.data.LightCurves.plot", "modulename": "src.utils.data", "qualname": "LightCurves.plot", "kind": "function", "doc": "<h1 id=\"plotting-the-full-simulation\">Plotting the full simulation</h1>\n\n<p>We create a plot of all simulations and all quarters.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utils.data.LightCurves.make_label", "modulename": "src.utils.data", "qualname": "LightCurves.make_label", "kind": "function", "doc": "<h1 id=\"for-each-quarter-we-compute-the-label\">For each quarter we compute the label</h1>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utils.data.plot", "modulename": "src.utils.data", "qualname": "plot", "kind": "function", "doc": "<h1 id=\"plots-the-given-list-of-simulation-index\">Plots the given list of simulation index</h1>\n\n<p>We use multiprocessing to speed computation up.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">cfg</span><span class=\"p\">:</span> <span class=\"nb\">dict</span>, </span><span class=\"param\"><span class=\"n\">plot_list</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utils.data.plotall", "modulename": "src.utils.data", "qualname": "plotall", "kind": "function", "doc": "<h1 id=\"creates-the-complete-list-of-files-to-plot\">Creates the complete list of files to plot</h1>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">cfg</span><span class=\"p\">:</span> <span class=\"nb\">dict</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utils.data.make_labels", "modulename": "src.utils.data", "qualname": "make_labels", "kind": "function", "doc": "<h1 id=\"creates-the-labels-for-all-the-files\">Creates the labels for all the files</h1>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">cfg</span><span class=\"p\">:</span> <span class=\"nb\">dict</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utils.plotter", "modulename": "src.utils.plotter", "kind": "module", "doc": "<h1 id=\"plotter-script\">Plotter script</h1>\n\n<p>Loads the light curves used for the training and plots them.</p>\n"}, {"fullname": "src.utils.plotter.PlatoLC", "modulename": "src.utils.plotter", "qualname": "PlatoLC", "kind": "class", "doc": "<h1 id=\"plato-light-curve\">Plato light curve</h1>\n\n<p>We represent the Plato light curve as a class, to be able to interact with it easily</p>\n"}, {"fullname": "src.utils.plotter.PlatoLC.__init__", "modulename": "src.utils.plotter", "qualname": "PlatoLC.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path_data</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">simulation_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "src.utils.plotter.PlatoLC.plot", "modulename": "src.utils.plotter", "qualname": "PlatoLC.plot", "kind": "function", "doc": "<h1 id=\"plots-the-flux-from-the-loaded-cameras\">Plots the flux from the loaded cameras</h1>\n\n<h2 id=\"description\">Description</h2>\n\n<p>Takes all the camera (or camera groups) contained in the file and plots them.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utils.plotter.plot_lc", "modulename": "src.utils.plotter", "qualname": "plot_lc", "kind": "function", "doc": "<h1 id=\"the-plotting-function\">The plotting function</h1>\n\n<h2 id=\"description\">Description</h2>\n\n<p>Takes the list of inputs (or fetches all if 'all' is the only element in the list) and plots them\nto help data visualization.</p>\n\n<h2 id=\"inputs\">Inputs</h2>\n\n<ul>\n<li><code>cfg</code>: Configuration file to use</li>\n<li><code>plot_list</code>: the list of files to be plotted</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">cfg</span><span class=\"p\">:</span> <span class=\"nb\">dict</span>, </span><span class=\"param\"><span class=\"n\">plot_list</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utils.prepare", "modulename": "src.utils.prepare", "kind": "module", "doc": "<h1 id=\"augmenting-the-data-to-be-used-for-training\">Augmenting the data to be used for training</h1>\n\n<p>Note that the creation of labels has to have happened previously.</p>\n"}, {"fullname": "src.utils.prepare.inspect_lc", "modulename": "src.utils.prepare", "qualname": "inspect_lc", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">root</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">lc_name</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utils.prepare.package", "modulename": "src.utils.prepare", "qualname": "package", "kind": "function", "doc": "<h1 id=\"packaging-the-simulation-files-into-the-pt-format-for-training\">Packaging the simulation files into the .pt format for training.</h1>\n\n<p>To simplify loading during training, we directly create a torch file with the lc and reference.</p>\n\n<p>We also have the possibility of augmenting the data by flipping the data time-wise. This is\ndone by fitting a spline with a long fit window to only detrend from the long term effect.\nWe output two files, the <code>O</code> and <code>A</code> version for the same light curve, original and augmented,\nrespectively.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">cfg</span><span class=\"p\">:</span> <span class=\"nb\">dict</span>, </span><span class=\"param\"><span class=\"n\">augment</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>, </span><span class=\"param\"><span class=\"n\">filter_invalid</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utils.prepare.write_file", "modulename": "src.utils.prepare", "qualname": "write_file", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">obj</span>, </span><span class=\"param\"><span class=\"n\">f_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utils.prepare.inspect", "modulename": "src.utils.prepare", "qualname": "inspect", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">l</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>, </span><span class=\"param\"><span class=\"n\">cfg</span><span class=\"p\">:</span> <span class=\"nb\">dict</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utils.recovery", "modulename": "src.utils.recovery", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.utils.recovery.get_boxes", "modulename": "src.utils.recovery", "qualname": "get_boxes", "kind": "function", "doc": "<h1 id=\"computes-the-boxes-around-a-transit-event\">Computes the boxes around a transit event</h1>\n\n<p>Note that we return a 2D box, with fictitious coordinates in <code>y</code>. This allows to simply call the\n<code>torch</code> implementation of the IOU computation for bounding boxes: <code>box_iou</code>. We always return \n<code>ymin, ymax = 0, 1</code> so as to always have a perfect match in that dimension.</p>\n\n<ul>\n<li><code>arr</code>: the tensor with the detection probability, shape [N]</li>\n<li><code>thr</code>: the threshold for detection [0, 1]</li>\n</ul>\n\n<p>Returns a tensor of shape [N, 4], where each block is the coordinates of the bounding box.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">arr</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"n\">thr</span><span class=\"p\">:</span> <span class=\"nb\">float</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.utils.recovery.transit_recovery", "modulename": "src.utils.recovery", "qualname": "transit_recovery", "kind": "function", "doc": "<h1 id=\"evaluates-the-bounding-box-of-a-transit\">Evaluates the bounding box of a transit</h1>\n\n<p>Estimates whether the transit was retrieved in the data. Returns the list of radii that were found,\nas well as the list of transit that were present in the dataset.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">prediction</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">reference</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">sims_params</span><span class=\"p\">:</span> <span class=\"nb\">dict</span>,</span><span class=\"param\">\t<span class=\"n\">thr</span><span class=\"p\">:</span> <span class=\"nb\">float</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();